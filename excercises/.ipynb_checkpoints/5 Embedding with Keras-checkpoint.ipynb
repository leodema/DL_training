{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "An example of how to create text embedding in Keras.\n",
    "\n",
    "Please complete the code in the where you find the \"# complete here\" comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T06:19:31.464820Z",
     "start_time": "2019-03-19T06:19:25.807342Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is good pizza</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love Italian pizza</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The best pizza</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nice pizza</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Excellent pizza</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I love pizza</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The pizza was alright</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>disgusting pineapple pizza</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>not good pizza</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bad pizza</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>very bad pizza</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I had better pizza</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          text  sentiment\n",
       "0           This is good pizza          1\n",
       "1         I love Italian pizza          1\n",
       "2               The best pizza          1\n",
       "3                   nice pizza          1\n",
       "4              Excellent pizza          1\n",
       "5                 I love pizza          1\n",
       "6        The pizza was alright          0\n",
       "7   disgusting pineapple pizza          0\n",
       "8               not good pizza          0\n",
       "9                    bad pizza          0\n",
       "10              very bad pizza          0\n",
       "11          I had better pizza          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "import pandas as pd\n",
    "\n",
    "# define the corpus\n",
    "corpus = ['This is good pizza',\n",
    "        'I love Italian pizza',\n",
    "        'The best pizza',\n",
    "        'nice pizza',\n",
    "        'Excellent pizza',\n",
    "        'I love pizza',\n",
    "        'The pizza was alright',\n",
    "        'disgusting pineapple pizza',\n",
    "        'not good pizza',\n",
    "        'bad pizza',\n",
    "        'very bad pizza',\n",
    "        'I had better pizza']\n",
    "\n",
    "\n",
    "# creating class labels for our \n",
    "labels = array([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "output_dim = 8\n",
    "pd.DataFrame({'text': corpus, 'sentiment':labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T06:19:31.479844Z",
     "start_time": "2019-03-19T06:19:31.468697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 5, 15],\n",
       " [1, 16, 10, 15],\n",
       " [17, 12, 15],\n",
       " [16, 15],\n",
       " [14, 15],\n",
       " [1, 16, 15],\n",
       " [17, 15, 15, 2],\n",
       " [18, 7, 15],\n",
       " [8, 5, 15],\n",
       " [11, 15],\n",
       " [3, 11, 15],\n",
       " [1, 14, 17, 15]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we extract the vocabulary from our corpus\n",
    "sentences = [voc.split() for voc in corpus]\n",
    "vocabulary = set([word for sentence in sentences for word in sentence])\n",
    "\n",
    "vocab_size = len(vocabulary)\n",
    "encoded_corpus = [one_hot(d, vocab_size) for d in corpus]\n",
    "encoded_corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T06:28:03.295360Z",
     "start_time": "2019-03-19T06:28:03.289117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Excellent',\n",
       " 'I',\n",
       " 'Italian',\n",
       " 'The',\n",
       " 'This',\n",
       " 'alright',\n",
       " 'bad',\n",
       " 'best',\n",
       " 'better',\n",
       " 'disgusting',\n",
       " 'good',\n",
       " 'had',\n",
       " 'is',\n",
       " 'love',\n",
       " 'nice',\n",
       " 'not',\n",
       " 'pineapple',\n",
       " 'pizza',\n",
       " 'very',\n",
       " 'was'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T06:19:31.496036Z",
     "start_time": "2019-03-19T06:19:31.484887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  5 15  0]\n",
      " [ 1 16 10 15  0]\n",
      " [17 12 15  0  0]\n",
      " [16 15  0  0  0]\n",
      " [14 15  0  0  0]\n",
      " [ 1 16 15  0  0]\n",
      " [17 15 15  2  0]\n",
      " [18  7 15  0  0]\n",
      " [ 8  5 15  0  0]\n",
      " [11 15  0  0  0]\n",
      " [ 3 11 15  0  0]\n",
      " [ 1 14 17 15  0]]\n"
     ]
    }
   ],
   "source": [
    "# we now pad the documents to  \n",
    "# the max length of the longest sentences\n",
    "# to have an uniform length\n",
    "max_length = 5\n",
    "padded_docs = pad_sequences(encoded_corpus, maxlen=max_length, padding='post')\n",
    "print(padded_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T06:19:33.998096Z",
     "start_time": "2019-03-19T06:19:31.500959Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 5, 8)              160       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 201\n",
      "Trainable params: 201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Accuracy: 91.666669\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model definition\n",
    "model = Sequential()\n",
    "model.add(Embedding(# complete here\n",
    "model.add(# complete here\n",
    "model.add(# complete here\n",
    "model.add(# compile the model\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
